# -*- coding: utf-8 -*-
"""B·∫£n sao c·ªßa LAY DATA CK.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bad_CMyOCc1Kc_lY_qhdj-RAhrFSyUuI
"""

import pandas as pd

# ƒê∆∞·ªùng d·∫´n file (thay n·∫øu em ƒë·∫∑t t√™n kh√°c ho·∫∑c folder kh√°c)
merged_path = "Merged_Full_Data_FINAL.xlsx"  # Ho·∫∑c "/content/Merged_Full_Data_FINAL.xlsx"
price_path = "VN_Stocks_Daily_Filtered_600_Sessions (1).xlsx"  # Ho·∫∑c "/content/VN_Stocks_Daily_Filtered_600_Sessions (1).xlsx"

# ƒê·ªçc file
try:
    fund_df = pd.read_excel(merged_path)
    price_df = pd.read_excel(price_path)
    print("‚úÖ ƒê·ªçc file th√†nh c√¥ng!")
    print(f"Fundamental data: {fund_df.shape[0]} rows, {fund_df.shape[1]} columns")
    print(f"Price data: {price_df.shape[0]} rows, {price_df.shape[1]} columns")
    print("\nFundamental columns:", fund_df.columns.tolist())
    print("Price columns:", price_df.columns.tolist())
except FileNotFoundError as e:
    print("‚ùå Kh√¥ng t√¨m th·∫•y file:", e)
    print("Ki·ªÉm tra t√™n file ho·∫∑c ƒë∆∞·ªùng d·∫´n. Th∆∞·ªùng file n·∫±m ·ªü /content/")
    import os
    print("C√°c file hi·ªán c√≥:", os.listdir('/content') if os.path.exists('/content') else os.listdir('.'))

# L∆∞u th√†nh CSV ƒë·ªÉ d√πng trong dashboard (t√πy ch·ªçn)
fund_df.to_csv("FUNDAMENTAL_FOR_PORTFOLIO.csv", index=False)
price_df.to_csv("PRICE_FOR_PORTFOLIO.csv", index=False)
print("\nƒê√£ l∆∞u th√†nh CSV ƒë·ªÉ d√πng trong dashboard!")

# ===============================
# PH√ÇN LO·∫†I NG√ÄNH THEO KH·∫®U V·ªä R·ª¶I RO
# ===============================

sector_risk_map = {
    # üî¥ TƒÇNG TR∆Ø·ªûNG / CHU K·ª≤ CAO (Aggressive)
    'IT Services': 'Aggressive',
    'Software': 'Aggressive',
    'Technology Hardware, Storage & Peripherals': 'Aggressive',
    'Semiconductors & Semiconductor Equipment': 'Aggressive',
    'Media': 'Aggressive',
    'Entertainment': 'Aggressive',
    'Interactive Media & Services': 'Aggressive',
    'Consumer Discretionary': 'Aggressive',
    'Automobiles': 'Aggressive',
    'Energy': 'Aggressive',
    'Oil, Gas & Consumable Fuels': 'Aggressive',
    'Real Estate Management & Development': 'Aggressive',
    'Real Estate': 'Aggressive',
    'Materials': 'Aggressive',
    'Chemicals': 'Aggressive',

    # üü° TRUNG T√çNH (Moderate)
    'Banks': 'Moderate',
    'Capital Markets': 'Moderate',
    'Insurance': 'Moderate',
    'Financial Services': 'Moderate',
    'Industrial Conglomerates': 'Moderate',
    'Construction & Engineering': 'Moderate',
    'Machinery': 'Moderate',
    'Transportation': 'Moderate',
    'Logistics': 'Moderate',

    # üü¢ PH√íNG TH·ª¶ (Conservative)
    'Health Care Equipment & Supplies': 'Conservative',
    'Health Care Providers & Services': 'Conservative',
    'Pharmaceuticals': 'Conservative',
    'Utilities': 'Conservative',
    'Electric Utilities': 'Conservative',
    'Water Utilities': 'Conservative',
    'Consumer Staples': 'Conservative',
    'Food Products': 'Conservative',
    'Beverages': 'Conservative',
    'Household Products': 'Conservative',
    'Telecommunication Services': 'Conservative'
}

import pandas as pd

path_price_check = "VN_Stocks_Daily_Filtered_600_Sessions (1).xlsx"
try:
    df_price_check = pd.read_excel(path_price_check)
    print(f"‚úÖ {path_price_check} loaded successfully!")
    display(df_price_check.head())
    df_price_check.info()
except Exception as e:
    print(f"‚ùå Error loading {path_price_check}: {e}")

import pandas as pd

# ===============================
# LOAD DATA
# ===============================

path_merged = "Merged_Full_Data_FINAL.xlsx"
path_price = "VN_Stocks_Daily_Filtered_600_Sessions (1).xlsx"

df_fundamental = pd.read_excel(path_merged)
df_price = pd.read_excel(path_price)

print("‚úÖ Fundamental DF shape:", df_fundamental.shape)
print("‚úÖ Price DF shape:", df_price.shape)

import pandas as pd

path_price_check = "VN_Stocks_Daily_Filtered_600_Sessions (1).xlsx"
df_price_check = pd.read_excel(path_price_check)

print("‚úÖ VN_Stocks_Daily_Filtered_600_Sessions (1).xlsx loaded successfully!")
display(df_price_check.head())
df_price_check.info()

import pandas as pd

path_merged = "Merged_Full_Data_FINAL.xlsx"
df_merged_check = pd.read_excel(path_merged)

print("‚úÖ Merged_Full_Data_FINAL.xlsx loaded successfully!")
display(df_merged_check.head())
df_merged_check.info()

print("üìå Fundamental columns:")
print(df_fundamental.columns)

print("\nüìå Price columns:")
print(df_price.columns)

import pandas as pd

# ==============================
# 1. LOAD FUNDAMENTAL DATA
# ==============================
fundamental_path = "Merged_Full_Data_FINAL.xlsx"

df_fund = pd.read_excel(fundamental_path)

print("‚úÖ Load Fundamental DF th√†nh c√¥ng")
print("Shape ban ƒë·∫ßu:", df_fund.shape)

# ==============================
# 2. CHU·∫®N H√ìA DATE
# ==============================
df_fund['DATE'] = pd.to_datetime(df_fund['DATE'], errors='coerce')

# ==============================
# 3. S·∫ÆP X·∫æP & GI·ªÆ K·ª≤ M·ªöI NH·∫§T
# ==============================
df_fund_latest = (
    df_fund
    .sort_values(['Symbol', 'DATE'], ascending=[True, False])
    .drop_duplicates(subset=['Symbol'], keep='first')
)

print("‚úÖ Sau khi gi·ªØ k·ª≥ m·ªõi nh·∫•t")
print("Shape:", df_fund_latest.shape)

# ==============================
# 4. GI·ªÆ C√ÅC C·ªòT C·∫¶N THI·∫æT
# ==============================
fundamental_cols = [
    'Symbol',
    'DATE',
    'Company Common Name',
    'GICS Industry Name',
    'EPS - Basic - excl Extraordinary Items, Common - Total',
    'Book Value per Share',
    'Beta 5 Year',
    'Dividend Yield - Common - Net - Issue - %, TTM',
    'Company Market Capitalization',
    'Net Income after Minority Interest',
    'Shareholders Equity - Common, PoP Avg'
]

df_fund_latest = df_fund_latest[fundamental_cols]

# ==============================
# 5. EXPORT FILE CHU·∫®N
# ==============================
output_path = "FUNDAMENTAL_LATEST_PER_SYMBOL.csv"
df_fund_latest.to_csv(output_path, index=False)

print("‚úÖ ƒê√£ xu·∫•t file:", output_path)

import pandas as pd

# ===============================
# 1Ô∏è‚É£ LOAD D·ªÆ LI·ªÜU
# ===============================
fund_df = pd.read_csv("FUNDAMENTAL_LATEST_PER_SYMBOL.csv")
price_df = pd.read_excel("VN_Stocks_Daily_Filtered_600_Sessions (1).xlsx")

print(f"‚úÖ Fundamental DF shape: {fund_df.shape}")
print(f"‚úÖ Price DF shape: {price_df.shape}")

# ===============================
# 2Ô∏è‚É£ PH√ÇN LO·∫†I NG√ÄNH (Sector / Industry)
# ===============================
sector_map_full = {
    # C√¥ng ngh·ªá th√¥ng tin
    'Information Technology': 'C√¥ng ngh·ªá th√¥ng tin',
    'IT Services': 'C√¥ng ngh·ªá th√¥ng tin',
    'Electronic Equipment, Instruments & Components': 'C√¥ng ngh·ªá th√¥ng tin',

    # H√†ng ti√™u d√πng kh√¥ng thi·∫øt y·∫øu
    'Consumer Discretionary': 'H√†ng ti√™u d√πng kh√¥ng thi·∫øt y·∫øu',
    'Textiles, Apparel & Luxury Goods': 'H√†ng ti√™u d√πng kh√¥ng thi·∫øt y·∫øu',
    'Specialty Retail': 'H√†ng ti√™u d√πng kh√¥ng thi·∫øt y·∫øu',
    'Household Durables': 'H√†ng ti√™u d√πng kh√¥ng thi·∫øt y·∫øu',
    'Leisure Products': 'H√†ng ti√™u d√πng kh√¥ng thi·∫øt y·∫øu',
    'Automobiles': 'H√†ng ti√™u d√πng kh√¥ng thi·∫øt y·∫øu',

    # H√†ng ti√™u d√πng thi·∫øt y·∫øu
    'Consumer Staples': 'H√†ng ti√™u d√πng thi·∫øt y·∫øu',
    'Food Products': 'H√†ng ti√™u d√πng thi·∫øt y·∫øu',
    'Beverages': 'H√†ng ti√™u d√πng thi·∫øt y·∫øu',
    'Household Products': 'H√†ng ti√™u d√πng thi·∫øt y·∫øu',
    'Tobacco': 'H√†ng ti√™u d√πng thi·∫øt y·∫øu',

    # Ng√¢n h√†ng & T√†i ch√≠nh
    'Banks': 'Ng√¢n h√†ng & T√†i ch√≠nh',
    'Capital Markets': 'Ng√¢n h√†ng & T√†i ch√≠nh',
    'Financial Services': 'Ng√¢n h√†ng & T√†i ch√≠nh',
    'Insurance': 'Ng√¢n h√†ng & T√†i ch√≠nh',

    # Y t·∫ø
    'Health Care Providers & Services': 'Y t·∫ø',
    'Pharmaceuticals': 'Y t·∫ø',

    # NƒÉng l∆∞·ª£ng
    'Energy Equipment & Services': 'NƒÉng l∆∞·ª£ng',
    'Oil, Gas & Consumable Fuels': 'NƒÉng l∆∞·ª£ng',
    'Independent Power and Renewable Electricity Producers': 'NƒÉng l∆∞·ª£ng',

    # B·∫•t ƒë·ªông s·∫£n
    'Real Estate Management & Development': 'B·∫•t ƒë·ªông s·∫£n',

    # Ti·ªán √≠ch
    'Electric Utilities': 'Ti·ªán √≠ch',
    'Water Utilities': 'Ti·ªán √≠ch',
    'Gas Utilities': 'Ti·ªán √≠ch',

    # D·ªãch v·ª• & gi·∫£i tr√≠ / c√¥ng nghi·ªáp kh√°c
    'Construction & Engineering': 'C√¥ng nghi·ªáp',
    'Construction Materials': 'C√¥ng nghi·ªáp',
    'Industrial Conglomerates': 'C√¥ng nghi·ªáp',
    'Machinery': 'C√¥ng nghi·ªáp',
    'Automobile Components': 'C√¥ng nghi·ªáp',
    'Transportation Infrastructure': 'C√¥ng nghi·ªáp',
    'Air Freight & Logistics': 'C√¥ng nghi·ªáp',
    'Marine Transportation': 'C√¥ng nghi·ªáp',
    'Ground Transportation': 'C√¥ng nghi·ªáp',
    'Containers & Packaging': 'C√¥ng nghi·ªáp',
    'Building Products': 'C√¥ng nghi·ªáp',
    'Paper & Forest Products': 'C√¥ng nghi·ªáp',
    'Electrical Equipment': 'C√¥ng nghi·ªáp',
    'Trading Companies & Distributors': 'C√¥ng nghi·ªáp',
    'Distributors': 'C√¥ng nghi·ªáp',

    'Hotels, Restaurants & Leisure': 'D·ªãch v·ª• & gi·∫£i tr√≠',
    'Professional Services': 'D·ªãch v·ª• & gi·∫£i tr√≠',
    'Commercial Services & Supplies': 'D·ªãch v·ª• & gi·∫£i tr√≠',
    'Media': 'D·ªãch v·ª• & gi·∫£i tr√≠',
    'Entertainment': 'D·ªãch v·ª• & gi·∫£i tr√≠',
    'Diversified Consumer Services': 'D·ªãch v·ª• & gi·∫£i tr√≠',
    'Diversified Telecommunication Services': 'D·ªãch v·ª• & gi·∫£i tr√≠',
}

fund_df['Sector_Group'] = fund_df['GICS Industry Name'].map(sector_map_full).fillna('Kh√°c')

print("‚úÖ Ph√¢n lo·∫°i ng√†nh xong")
print(fund_df['Sector_Group'].value_counts())

# ===============================
# 3Ô∏è‚É£ L·ªåC C·ªî PHI·∫æU THEO CRITERIA FUNDAMENTAL
# ===============================
filtered_df = fund_df[
    (fund_df['EPS - Basic - excl Extraordinary Items, Common - Total'] > 0) &
    (fund_df['Beta 5 Year'] < 1.5) &
    (fund_df['Company Market Capitalization'] > 25_000_000_000_000)  # > 1 t·ª∑ VNƒê
]

print(f"‚úÖ S·ªë c·ªï phi·∫øu sau khi l·ªçc: {filtered_df.shape[0]}")

# ===============================
# 4Ô∏è‚É£ L·ªåC D·ªÆ LI·ªÜU GI√Å THEO SYMBOL
# ===============================
price_filtered = price_df[price_df['Symbol'].isin(filtered_df['Symbol'])]
print(f"‚úÖ S·ªë d√≤ng d·ªØ li·ªáu gi√° c√≤n l·∫°i: {price_filtered.shape[0]}")

# ===============================
# 5Ô∏è‚É£ XU·∫§T FILE CHU·∫®N CHO T·ªêI ∆ØU DANH M·ª§C
# ===============================
filtered_df.to_csv("FUNDAMENTAL_FOR_PORTFOLIO.csv", index=False)
price_filtered.to_csv("PRICE_FOR_PORTFOLIO.csv", index=False)

print("‚úÖ ƒê√£ xu·∫•t 2 file chu·∫©n: FUNDAMENTAL_FOR_PORTFOLIO.csv & PRICE_FOR_PORTFOLIO.csv")

import pandas as pd

# Load l·∫°i d·ªØ li·ªáu ƒë√£ xu·∫•t
fund_df = pd.read_csv("FUNDAMENTAL_FOR_PORTFOLIO.csv")
price_df = pd.read_csv("PRICE_FOR_PORTFOLIO.csv")

# ‚úÖ Ki·ªÉm tra th√¥ng tin t·ªïng quan
print("=== Fundamental DF ===")
print(f"Shape: {fund_df.shape}")
print(fund_df.head())
print("\nSector_Group counts:")
print(fund_df['Sector_Group'].value_counts())

print("\n=== Price DF ===")
print(f"Shape: {price_df.shape}")
print(price_df.head())

# ‚úÖ Ki·ªÉm tra s·ªë l∆∞·ª£ng c·ªï phi·∫øu duy nh·∫•t
print(f"\nUnique symbols in fundamental DF: {fund_df['Symbol'].nunique()}")
print(f"Unique symbols in price DF: {price_df['Symbol'].nunique()}")

# ‚úÖ Ki·ªÉm tra kho·∫£ng th·ªùi gian d·ªØ li·ªáu gi√°
price_df['Date'] = pd.to_datetime(price_df['Date']) # ƒê√£ s·ª≠a 'DATE' th√†nh 'Date'
print(f"Price data range: {price_df['Date'].min()} to {price_df['Date'].max()}")



# Code dashboard ‚Äì ph√¢n lo·∫°i n·ªõi l·ªèng cho T√≠ch c·ª±c + dark mode ƒë·∫πp
code = '''
import streamlit as st
import pandas as pd
import numpy as np
from scipy.optimize import minimize
import plotly.express as px
import plotly.graph_objects as go

# Load d·ªØ li·ªáu
@st.cache_data
def load_data():
    fund = pd.read_csv("FUNDAMENTAL_FOR_PORTFOLIO.csv")
    price = pd.read_csv("PRICE_FOR_PORTFOLIO.csv")
    if 'Date' in price.columns:
        price['DATE'] = pd.to_datetime(price['Date'])
    else:
        price['DATE'] = pd.to_datetime(price['DATE'])
    return fund, price

fund_df, price_df = load_data()

# X·ª≠ l√Ω d·ªØ li·ªáu gi√°
price_df = price_df.drop_duplicates(subset=['DATE', 'Symbol'])
price_df = price_df.sort_values(['DATE', 'Symbol'])
price_pivot = price_df.pivot(index='DATE', columns='Symbol', values='Close')
price_pivot = price_pivot.ffill().bfill()
log_return = np.log(price_pivot / price_pivot.shift(1)).dropna(how='all')

# T√≠nh ROE, P/E n·∫øu ch∆∞a c√≥
if 'ROE' not in fund_df.columns:
    fund_df['ROE'] = fund_df['Net Income after Minority Interest'] / fund_df['Shareholders Equity - Common, PoP Avg'] * 100

latest_close = price_df.sort_values(['Symbol', 'DATE'], ascending=[True, False]).drop_duplicates('Symbol')[['Symbol', 'Close']]
fund_df = fund_df.merge(latest_close, on='Symbol', how='left')

if 'P/E' not in fund_df.columns:
    fund_df['P/E'] = fund_df['Close'] / fund_df['EPS - Basic - excl Extraordinary Items, Common - Total']
    fund_df['P/E'] = fund_df['P/E'].replace([np.inf, -np.inf], np.nan).fillna(0)

# Danh s√°ch ng√†nh
aggressive = ['IT Services', 'Software', 'Technology Hardware, Storage & Peripherals', 'Retail', 'Textiles, Apparel & Luxury Goods',
              'Oil, Gas & Consumable Fuels', 'Chemicals', 'Real Estate Management & Development', 'Construction & Engineering',
              'Metals & Mining', 'Transportation']

conservative = ['Pharmaceuticals', 'Health Care Equipment & Services', 'Utilities', 'Independent Power and Renewable Electricity Producers',
                'Food Products', 'Beverages', 'Household Products', 'Banks']

# Ph√¢n lo·∫°i kh·∫©u v·ªã r·ªßi ro ‚Äì N·ªöI L·ªéNG CHO T√çCH C·ª∞C
def classify(row):
    # T√≠ch c·ª±c: ƒëi·ªÉm s·ªë √≠t nh·∫•t 3/4 ti√™u ch√≠ + ∆∞u ti√™n ng√†nh aggressive
    score_aggressive = sum([
        row['ROE'] > 15,
        row['Beta 5 Year'] > 1.0,
        row['P/E'] > 20,
        row['GICS Industry Name'] in aggressive
    ])
    if score_aggressive >= 3:
        return "T√≠ch c·ª±c"

    # B·∫£o th·ªß: gi·ªØ nguy√™n nghi√™m ng·∫∑t
    elif (row['Company Market Capitalization'] > 25_000_000_000_000 and
          row['Dividend Yield - Common - Net - Issue - %, TTM'] > 1.5 and
          row['Beta 5 Year'] < 1.2 and row['ROE'] > 10 and
          row['GICS Industry Name'] in conservative):
        return "B·∫£o th·ªß"

    # C√¢n b·∫±ng: n·ªõi nh·∫π
    else:
        score = sum([
            row['ROE'] > 12,
            0.8 <= row['Beta 5 Year'] <= 1.3,
            row['Dividend Yield - Common - Net - Issue - %, TTM'] > 1.0,
            row['P/E'] > 12
        ])
        return "C√¢n b·∫±ng" if score >= 2 else "Kh√°c"

if 'Khau_Vi_Rui_Ro' not in fund_df.columns:
    fund_df = fund_df.dropna(subset=['ROE', 'Beta 5 Year', 'P/E', 'GICS Industry Name',
                                     'Dividend Yield - Common - Net - Issue - %, TTM'])
    fund_df['Khau_Vi_Rui_Ro'] = fund_df.apply(classify, axis=1)

# H√†m t√≠nh hi·ªáu qu·∫£ ‚Äì annualize ƒë√∫ng
def expected_return(weights, log_returns):
    return np.sum(log_returns.mean() * weights) * 252 * 100

def standard_deviation(weights, cov_matrix):
    variance = weights.T @ cov_matrix @ weights
    return np.sqrt(variance * 252) * 100

def sharpe_ratio(weights, log_returns, cov_matrix, risk_free_rate):
    ret = expected_return(weights, log_returns) / 100
    vol = standard_deviation(weights, cov_matrix) / 100
    return (ret - risk_free_rate) / vol if vol > 0 else 0

def neg_sharpe_ratio(weights, log_returns, cov_matrix, risk_free_rate):
    return -sharpe_ratio(weights, log_returns, cov_matrix, risk_free_rate)

def optimize_portfolio(log_returns_query, risk_free_rate):
    stock_list = log_returns_query.columns.tolist()

    correlation_matrix = log_returns_query.corr()
    std_devs = log_returns_query.std()
    covariance_matrix = correlation_matrix.to_numpy() * np.outer(std_devs, std_devs)
    covariance_df = pd.DataFrame(covariance_matrix, columns=log_returns_query.columns, index=log_returns_query.columns)

    constraints = {'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1}
    bounds = [(0, 0.4) for _ in range(len(stock_list))]
    initial_weights = np.array([1/len(stock_list)] * len(stock_list))

    optimized_results = minimize(neg_sharpe_ratio, initial_weights,
                                 args=(log_returns_query, covariance_df, risk_free_rate),
                                 method='SLSQP', constraints=constraints, bounds=bounds)

    return optimized_results.x if optimized_results.success else initial_weights

# Risk-free rate VN th·ª±c t·∫ø
risk_free_rate = 0.0418
st.sidebar.success("Risk-free rate VN (TPCP 10 nƒÉm): 4.18% (d·ªØ li·ªáu 30/12/2025)")

# Giao di·ªán
st.title("üéØ B·∫£ng ƒêi·ªÅu Khi·ªÉn Danh M·ª•c ƒê·∫ßu T∆∞ T·ªëi ∆Øu (Bluechip VN)")

st.sidebar.info("D·ªØ li·ªáu: 41 c·ªï phi·∫øu bluechip l·ªõn nh·∫•t HOSE")

khau_vi = st.sidebar.selectbox("Ch·ªçn kh·∫©u v·ªã r·ªßi ro", ["B·∫£o th·ªß", "C√¢n b·∫±ng", "T√≠ch c·ª±c"])

filtered = fund_df[fund_df['Khau_Vi_Rui_Ro'] == khau_vi].set_index('Symbol')

if filtered.empty:
    st.info(f"Kh√¥ng c√≥ c·ªï phi·∫øu n√†o thu·ªôc kh·∫©u v·ªã '{khau_vi}'.")
else:
    st.markdown(f"<h2 style='color: #2ca02c;'>C·ªï phi·∫øu ph√π h·ª£p cho {khau_vi}</h2>", unsafe_allow_html=True)
    st.dataframe(filtered[['Company Common Name', 'ROE', 'Beta 5 Year', 'Dividend Yield - Common - Net - Issue - %, TTM', 'P/E']])

    symbols = [s for s in filtered.index if s in log_return.columns]
    if len(symbols) < 3:  # TƒÉng t·ª´ 2 l√™n 3 ƒë·ªÉ ch·∫Øc ch·∫Øn ƒëa d·∫°ng
        st.info(f"Ch·ªâ c√≥ {len(symbols)} c·ªï phi·∫øu ‚Äì ch∆∞a ƒë·ªß ƒë·ªÉ t·ªëi ∆∞u danh m·ª•c ƒëa d·∫°ng (c·∫ßn √≠t nh·∫•t 3).")
    else:
        log_returns_query = log_return[symbols]
        optimal_weights = optimize_portfolio(log_returns_query, risk_free_rate)

        portfolio_df = pd.DataFrame({'Ticker': symbols, 'Weight': optimal_weights})
        portfolio_df = portfolio_df[portfolio_df['Weight'] > 0.0001].sort_values('Weight', ascending=False)

        # Dividend Yield danh m·ª•c
        merged = portfolio_df.merge(filtered[['Dividend Yield - Common - Net - Issue - %, TTM']], left_on='Ticker', right_index=True)
        dividend_yield_port = (merged['Weight'] * merged['Dividend Yield - Common - Net - Issue - %, TTM']).sum()

        # Hi·ªáu qu·∫£ danh m·ª•c
        optimal_return = expected_return(optimal_weights, log_returns_query)
        optimal_vol = standard_deviation(optimal_weights, log_returns_query.cov())
        optimal_sharpe = sharpe_ratio(optimal_weights, log_returns_query, log_returns_query.cov(), risk_free_rate)

        # Hi·ªÉn th·ªã
        st.markdown("<h2 style='color: #1f77b4;'>Th√¥ng tin danh m·ª•c t·ªëi ∆∞u</h2>", unsafe_allow_html=True)
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("L·ª£i nhu·∫≠n k·ª≥ v·ªçng", f"{optimal_return:.1f}%")
        col2.metric("Bi·∫øn ƒë·ªông", f"{optimal_vol:.1f}%")
        col3.metric("Sharpe Ratio", f"{optimal_sharpe:.2f}")
        col4.metric("Dividend Yield", f"{dividend_yield_port:.2f}%")

        # Pie chart
        fig = px.pie(portfolio_df, values='Weight', names='Ticker', title='T·ª∑ tr·ªçng danh m·ª•c t·ªëi ∆∞u',
                     color_discrete_sequence=px.colors.sequential.Viridis)
        fig.update_traces(textinfo='percent+label', pull=[0.1 if w > 0.1 else 0 for w in portfolio_df['Weight']])
        st.plotly_chart(fig, use_container_width=True)

        # Correlation heatmap
        st.markdown("<h2 style='color: #9467bd;'>Ma tr·∫≠n t∆∞∆°ng quan c·ªï phi·∫øu trong danh m·ª•c</h2>", unsafe_allow_html=True)
        corr = log_returns_query.corr()
        fig_corr = go.Figure(data=go.Heatmap(
            z=corr.values,
            x=corr.columns,
            y=corr.index,
            colorscale='RdBu',
            zmin=-1, zmax=1,
            text=corr.values.round(2),
            texttemplate="%{text}",
            textfont={"size": 10},
            colorbar=dict(title="Correlation")
        ))
        fig_corr.update_layout(
            title="Ma tr·∫≠n t∆∞∆°ng quan log-return",
            height=600,
            xaxis_title="C·ªï phi·∫øu",
            yaxis_title="C·ªï phi·∫øu",
            xaxis=dict(tickangle=45),
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)'
        )
        st.plotly_chart(fig_corr, use_container_width=True)

        # L·ª£i nhu·∫≠n t√≠ch l≈©y
        st.markdown("<h2 style='color: #d62728;'>L·ª£i nhu·∫≠n t√≠ch l≈©y danh m·ª•c</h2>", unsafe_allow_html=True)
        portfolio_cumulative = (log_returns_query + 1).cumprod().dot(optimal_weights)
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=portfolio_cumulative.index, y=portfolio_cumulative, name="Danh m·ª•c t·ªëi ∆∞u", line=dict(color="#1f77b4", width=2.5)))
        fig.update_layout(title="L·ª£i nhu·∫≠n t√≠ch l≈©y danh m·ª•c t·ªëi ∆∞u", xaxis_title="Ng√†y", yaxis_title="L·ª£i nhu·∫≠n t√≠ch l≈©y",
                          height=500, plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)')
        st.plotly_chart(fig, use_container_width=True)

# Custom CSS dark mode ƒë·∫πp
st.markdown("""
<style>
.stApp {
    background-color: #121212;
    color: #e0e0e0;
}
h1, h2, h3 {
    color: #ffffff;
}
.stDataFrame {
    background-color: #1e1e1e;
}
.stMetric {
    background-color: #1e1e1e;
    padding: 15px;
    border-radius: 10px;
    box-shadow: 0 4px 12px rgba(0,0,0,0.5);
    color: #ffffff;
    border: 1px solid #333333;
}
.stMetric > label {
    color: #aaaaaa;
    font-size: 0.9em;
}
.stSelectbox > div > div {
    background-color: #1e1e1e;
    color: #ffffff;
}
.stSidebar {
    background-color: #0e0e0e;
}
</style>
""", unsafe_allow_html=True)
'''

# Ghi file
with open("dashboard.py", "w") as f:
    f.write(code)


# Code dashboard ‚Äì th√™m so s√°nh benchmark VN-Index/VN30/VN100
code = '''
import streamlit as st
import pandas as pd
import numpy as np
from scipy.optimize import minimize
import plotly.express as px
import plotly.graph_objects as go

# Load d·ªØ li·ªáu bluechip
@st.cache_data
def load_data():
    fund = pd.read_csv("FUNDAMENTAL_FOR_PORTFOLIO.csv")
    price = pd.read_csv("PRICE_FOR_PORTFOLIO.csv")
    if 'Date' in price.columns:
        price['DATE'] = pd.to_datetime(price['Date'])
    else:
        price['DATE'] = pd.to_datetime(price['DATE'])
    return fund, price

fund_df, price_df = load_data()

# X·ª≠ l√Ω d·ªØ li·ªáu gi√° bluechip
price_df = price_df.drop_duplicates(subset=['DATE', 'Symbol'])
price_df = price_df.sort_values(['DATE', 'Symbol'])
price_pivot = price_df.pivot(index='DATE', columns='Symbol', values='Close')
price_pivot = price_pivot.ffill().bfill()
log_return = np.log(price_pivot / price_pivot.shift(1)).dropna(how='all')

# T√≠nh ROE, P/E
if 'ROE' not in fund_df.columns:
    fund_df['ROE'] = fund_df['Net Income after Minority Interest'] / fund_df['Shareholders Equity - Common, PoP Avg'] * 100

latest_close = price_df.sort_values(['Symbol', 'DATE'], ascending=[True, False]).drop_duplicates('Symbol')[['Symbol', 'Close']]
fund_df = fund_df.merge(latest_close, on='Symbol', how='left')

if 'P/E' not in fund_df.columns:
    fund_df['P/E'] = fund_df['Close'] / fund_df['EPS - Basic - excl Extraordinary Items, Common - Total']
    fund_df['P/E'] = fund_df['P/E'].replace([np.inf, -np.inf], np.nan).fillna(0)

# Danh s√°ch ng√†nh
aggressive = ['IT Services', 'Software', 'Technology Hardware, Storage & Peripherals', 'Retail', 'Textiles, Apparel & Luxury Goods',
              'Oil, Gas & Consumable Fuels', 'Chemicals', 'Real Estate Management & Development', 'Construction & Engineering',
              'Metals & Mining', 'Transportation']

conservative = ['Pharmaceuticals', 'Health Care Equipment & Services', 'Utilities', 'Independent Power and Renewable Electricity Producers',
                'Food Products', 'Beverages', 'Household Products', 'Banks']

# Ph√¢n lo·∫°i ‚Äì n·ªõi l·ªèng cho T√≠ch c·ª±c
def classify(row):
    score_aggressive = sum([
        row['ROE'] > 15,
        row['Beta 5 Year'] > 1.0,
        row['P/E'] > 20,
        row['GICS Industry Name'] in aggressive
    ])
    if score_aggressive >= 3:
        return "T√≠ch c·ª±c"

    elif (row['Company Market Capitalization'] > 25_000_000_000_000 and
          row['Dividend Yield - Common - Net - Issue - %, TTM'] > 1.5 and
          row['Beta 5 Year'] < 1.2 and row['ROE'] > 10 and
          row['GICS Industry Name'] in conservative):
        return "B·∫£o th·ªß"

    else:
        score = sum([
            row['ROE'] > 12,
            0.8 <= row['Beta 5 Year'] <= 1.3,
            row['Dividend Yield - Common - Net - Issue - %, TTM'] > 1.0,
            row['P/E'] > 12
        ])
        return "C√¢n b·∫±ng" if score >= 2 else "Kh√°c"

if 'Khau_Vi_Rui_Ro' not in fund_df.columns:
    fund_df = fund_df.dropna(subset=['ROE', 'Beta 5 Year', 'P/E', 'GICS Industry Name',
                                     'Dividend Yield - Common - Net - Issue - %, TTM'])
    fund_df['Khau_Vi_Rui_Ro'] = fund_df.apply(classify, axis=1)

# H√†m t√≠nh hi·ªáu qu·∫£
def expected_return(weights, log_returns):
    return np.sum(log_returns.mean() * weights) * 252 * 100

def standard_deviation(weights, cov_matrix):
    variance = weights.T @ cov_matrix @ weights
    return np.sqrt(variance * 252) * 100

def sharpe_ratio(weights, log_returns, cov_matrix, risk_free_rate):
    ret = expected_return(weights, log_returns) / 100
    vol = standard_deviation(weights, cov_matrix) / 100
    return (ret - risk_free_rate) / vol if vol > 0 else 0

def optimize_portfolio(log_returns_query, risk_free_rate):
    stock_list = log_returns_query.columns.tolist()
    correlation_matrix = log_returns_query.corr()
    std_devs = log_returns_query.std()
    covariance_matrix = correlation_matrix.to_numpy() * np.outer(std_devs, std_devs)
    constraints = {'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1}
    bounds = [(0, 0.4) for _ in range(len(stock_list))]
    initial_weights = np.array([1/len(stock_list)] * len(stock_list))
    optimized_results = minimize(lambda w: -sharpe_ratio(w, log_returns_query, covariance_matrix, risk_free_rate),
                                 initial_weights, method='SLSQP', constraints=constraints, bounds=bounds)
    return optimized_results.x if optimized_results.success else initial_weights

# Load benchmark (em thay t√™n file ƒë√∫ng)
@st.cache_data
def load_benchmark():
    vn_index = pd.read_csv("D·ªØ li·ªáu L·ªãch s·ª≠ VN Index.csv")
    vn30 = pd.read_csv("D·ªØ li·ªáu L·ªãch s·ª≠ VN 30.csv")
    vn100 = pd.read_csv("D·ªØ li·ªáu L·ªãch s·ª≠ VN100.csv")

    def process(df):
        df['Ng√†y'] = pd.to_datetime(df['Ng√†y'], format='%d/%m/%Y')
        df = df.sort_values('Ng√†y')
        df['Close'] = pd.to_numeric(df['L·∫ßn cu·ªëi'].str.replace(',', ''))
        df['log_return'] = np.log(df['Close'] / df['Close'].shift(1))
        log_r = df['log_return'].dropna()
        ret = log_r.mean() * 252 * 100
        vol = log_r.std() * np.sqrt(252) * 100
        sharpe = (ret/100 - 0.0418) / (vol/100) if vol > 0 else 0
        return round(ret, 1), round(vol, 1), round(sharpe, 2)

    benchmarks = {
        'VN-Index': process(vn_index),
        'VN30': process(vn30),
        'VN100': process(vn100)
    }
    return benchmarks

benchmarks = load_benchmark()

# Risk-free rate
risk_free_rate = 0.0418
st.sidebar.success("Risk-free rate VN (TPCP 10 nƒÉm): 4.18% (d·ªØ li·ªáu 30/12/2025)")

# Giao di·ªán
st.title("üéØ B·∫£ng ƒêi·ªÅu Khi·ªÉn Danh M·ª•c ƒê·∫ßu T∆∞ T·ªëi ∆Øu (Bluechip VN)")

st.sidebar.info("D·ªØ li·ªáu: 41 c·ªï phi·∫øu bluechip l·ªõn nh·∫•t HOSE")

khau_vi = st.sidebar.selectbox("Ch·ªçn kh·∫©u v·ªã r·ªßi ro", ["B·∫£o th·ªß", "C√¢n b·∫±ng", "T√≠ch c·ª±c"])

filtered = fund_df[fund_df['Khau_Vi_Rui_Ro'] == khau_vi].set_index('Symbol')

if filtered.empty:
    st.info(f"Kh√¥ng c√≥ c·ªï phi·∫øu n√†o thu·ªôc kh·∫©u v·ªã '{khau_vi}'.")
else:
    st.markdown(f"<h2 style='color: #2ca02c;'>C·ªï phi·∫øu ph√π h·ª£p cho {khau_vi}</h2>", unsafe_allow_html=True)
    st.dataframe(filtered[['Company Common Name', 'ROE', 'Beta 5 Year', 'Dividend Yield - Common - Net - Issue - %, TTM', 'P/E']])

    symbols = [s for s in filtered.index if s in log_return.columns]
    if len(symbols) < 3:
        st.info(f"Ch·ªâ c√≥ {len(symbols)} c·ªï phi·∫øu ‚Äì ch∆∞a ƒë·ªß ƒëa d·∫°ng.")
    else:
        log_returns_query = log_return[symbols]
        optimal_weights = optimize_portfolio(log_returns_query, risk_free_rate)

        portfolio_df = pd.DataFrame({'Ticker': symbols, 'Weight': optimal_weights})
        portfolio_df = portfolio_df[portfolio_df['Weight'] > 0.0001].sort_values('Weight', ascending=False)

        merged = portfolio_df.merge(filtered[['Dividend Yield - Common - Net - Issue - %, TTM']], left_on='Ticker', right_index=True)
        dividend_yield_port = (merged['Weight'] * merged['Dividend Yield - Common - Net - Issue - %, TTM']).sum()

        optimal_return = expected_return(optimal_weights, log_returns_query)
        optimal_vol = standard_deviation(optimal_weights, log_returns_query.cov())
        optimal_sharpe = sharpe_ratio(optimal_weights, log_returns_query, log_returns_query.cov(), risk_free_rate)

        st.markdown("<h2 style='color: #1f77b4;'>Th√¥ng tin danh m·ª•c t·ªëi ∆∞u</h2>", unsafe_allow_html=True)
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("L·ª£i nhu·∫≠n k·ª≥ v·ªçng", f"{optimal_return:.1f}%")
        col2.metric("Bi·∫øn ƒë·ªông", f"{optimal_vol:.1f}%")
        col3.metric("Sharpe Ratio", f"{optimal_sharpe:.2f}")
        col4.metric("Dividend Yield", f"{dividend_yield_port:.2f}%")

        # Pie chart, heatmap, cumulative nh∆∞ c≈©...
        # (gi·ªØ nguy√™n ph·∫ßn c≈©)

        # SO S√ÅNH BENCHMARK
        st.markdown("<h2 style='color: #ff7f0e;'>So s√°nh v·ªõi Benchmark (2020-2025)</h2>", unsafe_allow_html=True)
        comparison_data = [
            {"Nh√≥m": khau_vi, "Return (%)": optimal_return, "Vol (%)": optimal_vol, "Sharpe": optimal_sharpe},
            {"Nh√≥m": "VN-Index", "Return (%)": benchmarks['VN-Index'][0], "Vol (%)": benchmarks['VN-Index'][1], "Sharpe": benchmarks['VN-Index'][2]},
            {"Nh√≥m": "VN30", "Return (%)": benchmarks['VN30'][0], "Vol (%)": benchmarks['VN30'][1], "Sharpe": benchmarks['VN30'][2]},
            {"Nh√≥m": "VN100", "Return (%)": benchmarks['VN100'][0], "Vol (%)": benchmarks['VN100'][1], "Sharpe": benchmarks['VN100'][2]},
        ]
        df_comp = pd.DataFrame(comparison_data)
        st.dataframe(df_comp.style.highlight_max(subset=['Sharpe'], color='lightgreen'))

        # Bi·ªÉu ƒë·ªì scatter
        fig = go.Figure()
        for row in comparison_data:
            color = 'red' if row['Nh√≥m'] == khau_vi else 'gray'
            size = 20 if row['Nh√≥m'] == khau_vi else 10
            fig.add_trace(go.Scatter(x=[row['Vol (%)']], y=[row['Return (%)']], mode='markers+text',
                                     marker=dict(size=size, color=color), text=row['Nh√≥m'], textposition="top center"))
        fig.update_layout(title="So s√°nh Return vs Risk", xaxis_title="Bi·∫øn ƒë·ªông (%)", yaxis_title="L·ª£i nhu·∫≠n k·ª≥ v·ªçng (%)")
        st.plotly_chart(fig)

# Dark mode CSS
st.markdown("""
<style>
.stApp {background-color: #121212; color: #e0e0e0;}
h1, h2, h3 {color: #ffffff;}
.stDataFrame {background-color: #1e1e1e;}
.stMetric {background-color: #1e1e1e; padding: 15px; border-radius: 10px; box-shadow: 0 4px 12px rgba(0,0,0,0.5); color: #ffffff; border: 1px solid #333333;}
.stMetric > label {color: #aaaaaa;}
.stSidebar {background-color: #0e0e0e;}
</style>
""", unsafe_allow_html=True)
'''

